{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241f7df1-355a-4208-b541-db62e162fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7086a8ac-f1ad-42fb-abcd-2e63232b2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import llama_cpp\n",
    "import torch\n",
    "\n",
    "from curverag import utils\n",
    "from curverag.curverag import CurveRAG, DEFAULT_ENTITY_TYPES, DEFAULT_GLINER_MODEL, DEFAULT_SENTENCE_TRANSFORMER_MODEL\n",
    "from curverag.graph import KnowledgeGraph\n",
    "from curverag.atth.kg_dataset import KGDataset\n",
    "from curverag.atth.models.hyperbolic import AttH\n",
    "from curverag.eval import evaluation, queries, context, expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b350d8f-ffe3-4bbc-893b-3a60ec85e8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "load_dotenv() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e38b36b-99dc-4625-b58b-80dc8893de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:/Learning/hyperbolic-graph-rag/curverag/data/WN'\n",
    "dataset = KGDataset(data_path, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2921ba72-62c2-417d-9833-eaf3ff4b2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0150d4a6-a34d-46fa-bb92-486419e72f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f22960ce0648189a3e792cd88de201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Learning\\hyperbolic-graph-rag\\curverag\\.venv\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "entity_types = ['people', 'locations', 'entities', 'movies', 'directors']\n",
    "rag = CurveRAG(\n",
    "    openai_client=client,\n",
    "    entity_types=entity_types,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49bf88fa-141c-4be2-b225-a4c90add22fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 00:15:46,852 INFO     Saving logs in: ./logs/06_03\\name\\AttH_00_15_46\n",
      "2025-06-03 00:15:46,852 INFO     Saving logs in: ./logs/06_03\\name\\AttH_00_15_46\n",
      "2025-06-03 00:15:46,853 INFO     \t (40943, 36, 40943)\n",
      "2025-06-03 00:15:46,853 INFO     \t (40943, 36, 40943)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kg embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 00:15:47,837 INFO     Total number of parameters 41204922\n",
      "2025-06-03 00:15:47,837 INFO     Total number of parameters 41204922\n",
      "2025-06-03 00:15:47,860 INFO     \t Start training\n",
      "2025-06-03 00:15:47,860 INFO     \t Start training\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 57.33ex/s, loss=0.6884]\n",
      "2025-06-03 00:16:05,309 INFO     \t Epoch 0 | average train loss: 0.6884\n",
      "2025-06-03 00:16:05,309 INFO     \t Epoch 0 | average train loss: 0.6884\n",
      "2025-06-03 00:16:09,200 INFO     \t Epoch 0 | average valid loss: 2.0994\n",
      "2025-06-03 00:16:09,200 INFO     \t Epoch 0 | average valid loss: 2.0994\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 55.33ex/s, loss=2.1058]\n",
      "2025-06-03 00:16:27,276 INFO     \t Epoch 1 | average train loss: 2.1058\n",
      "2025-06-03 00:16:27,276 INFO     \t Epoch 1 | average train loss: 2.1058\n",
      "2025-06-03 00:16:31,313 INFO     \t Epoch 1 | average valid loss: 1.9894\n",
      "2025-06-03 00:16:31,313 INFO     \t Epoch 1 | average valid loss: 1.9894\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 54.68ex/s, loss=1.9917]\n",
      "2025-06-03 00:16:49,602 INFO     \t Epoch 2 | average train loss: 1.9917\n",
      "2025-06-03 00:16:49,602 INFO     \t Epoch 2 | average train loss: 1.9917\n",
      "2025-06-03 00:16:53,828 INFO     \t Epoch 2 | average valid loss: 1.7232\n",
      "2025-06-03 00:16:53,828 INFO     \t Epoch 2 | average valid loss: 1.7232\n",
      "2025-06-03 00:16:58,837 INFO     \t valid MR: 26522.10 | MRR: 0.000 | H@1: 0.000 | H@3: 0.000 | H@10: 0.000\n",
      "2025-06-03 00:16:58,837 INFO     \t valid MR: 26522.10 | MRR: 0.000 | H@1: 0.000 | H@3: 0.000 | H@10: 0.000\n",
      "2025-06-03 00:16:58,837 INFO     \t Epoch 2 | average valid mmr: 0.0002\n",
      "2025-06-03 00:16:58,837 INFO     \t Epoch 2 | average valid mmr: 0.0002\n",
      "2025-06-03 00:16:58,837 INFO     \t Saving model at epoch 2 in ./logs/06_03\\name\\AttH_00_15_46\n",
      "2025-06-03 00:16:58,837 INFO     \t Saving model at epoch 2 in ./logs/06_03\\name\\AttH_00_15_46\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 55.67ex/s, loss=1.2110]\n",
      "2025-06-03 00:17:17,688 INFO     \t Epoch 3 | average train loss: 1.2110\n",
      "2025-06-03 00:17:17,688 INFO     \t Epoch 3 | average train loss: 1.2110\n",
      "2025-06-03 00:17:21,703 INFO     \t Epoch 3 | average valid loss: 1.8572\n",
      "2025-06-03 00:17:21,703 INFO     \t Epoch 3 | average valid loss: 1.8572\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 55.63ex/s, loss=1.3603]\n",
      "2025-06-03 00:17:39,681 INFO     \t Epoch 4 | average train loss: 1.3603\n",
      "2025-06-03 00:17:39,681 INFO     \t Epoch 4 | average train loss: 1.3603\n",
      "2025-06-03 00:17:43,765 INFO     \t Epoch 4 | average valid loss: 1.6772\n",
      "2025-06-03 00:17:43,765 INFO     \t Epoch 4 | average valid loss: 1.6772\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 56.32ex/s, loss=0.4175]\n",
      "2025-06-03 00:18:01,524 INFO     \t Epoch 5 | average train loss: 0.4175\n",
      "2025-06-03 00:18:01,524 INFO     \t Epoch 5 | average train loss: 0.4175\n",
      "2025-06-03 00:18:05,558 INFO     \t Epoch 5 | average valid loss: 1.6485\n",
      "2025-06-03 00:18:05,558 INFO     \t Epoch 5 | average valid loss: 1.6485\n",
      "2025-06-03 00:18:10,653 INFO     \t valid MR: 25721.85 | MRR: 0.001 | H@1: 0.001 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:18:10,653 INFO     \t valid MR: 25721.85 | MRR: 0.001 | H@1: 0.001 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:18:10,655 INFO     \t Epoch 5 | average valid mmr: 0.0007\n",
      "2025-06-03 00:18:10,655 INFO     \t Epoch 5 | average valid mmr: 0.0007\n",
      "2025-06-03 00:18:10,658 INFO     \t Saving model at epoch 5 in ./logs/06_03\\name\\AttH_00_15_46\n",
      "2025-06-03 00:18:10,658 INFO     \t Saving model at epoch 5 in ./logs/06_03\\name\\AttH_00_15_46\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 56.30ex/s, loss=0.1780]\n",
      "2025-06-03 00:18:29,314 INFO     \t Epoch 6 | average train loss: 0.1780\n",
      "2025-06-03 00:18:29,314 INFO     \t Epoch 6 | average train loss: 0.1780\n",
      "2025-06-03 00:18:33,328 INFO     \t Epoch 6 | average valid loss: 1.6061\n",
      "2025-06-03 00:18:33,328 INFO     \t Epoch 6 | average valid loss: 1.6061\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 56.32ex/s, loss=0.0727]\n",
      "2025-06-03 00:18:51,092 INFO     \t Epoch 7 | average train loss: 0.0727\n",
      "2025-06-03 00:18:51,092 INFO     \t Epoch 7 | average train loss: 0.0727\n",
      "2025-06-03 00:18:55,141 INFO     \t Epoch 7 | average valid loss: 1.6054\n",
      "2025-06-03 00:18:55,141 INFO     \t Epoch 7 | average valid loss: 1.6054\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 54.94ex/s, loss=0.0296]\n",
      "2025-06-03 00:19:13,348 INFO     \t Epoch 8 | average train loss: 0.0296\n",
      "2025-06-03 00:19:13,348 INFO     \t Epoch 8 | average train loss: 0.0296\n",
      "2025-06-03 00:19:17,379 INFO     \t Epoch 8 | average valid loss: 1.5979\n",
      "2025-06-03 00:19:17,379 INFO     \t Epoch 8 | average valid loss: 1.5979\n",
      "2025-06-03 00:19:22,385 INFO     \t valid MR: 25870.03 | MRR: 0.000 | H@1: 0.000 | H@3: 0.000 | H@10: 0.001\n",
      "2025-06-03 00:19:22,385 INFO     \t valid MR: 25870.03 | MRR: 0.000 | H@1: 0.000 | H@3: 0.000 | H@10: 0.001\n",
      "2025-06-03 00:19:22,385 INFO     \t Epoch 8 | average valid mmr: 0.0003\n",
      "2025-06-03 00:19:22,385 INFO     \t Epoch 8 | average valid mmr: 0.0003\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 55.48ex/s, loss=0.0170]\n",
      "2025-06-03 00:19:40,414 INFO     \t Epoch 9 | average train loss: 0.0170\n",
      "2025-06-03 00:19:40,414 INFO     \t Epoch 9 | average train loss: 0.0170\n",
      "2025-06-03 00:19:44,608 INFO     \t Epoch 9 | average valid loss: 1.6039\n",
      "2025-06-03 00:19:44,608 INFO     \t Epoch 9 | average valid loss: 1.6039\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 54.93ex/s, loss=0.0153]\n",
      "2025-06-03 00:20:02,815 INFO     \t Epoch 10 | average train loss: 0.0153\n",
      "2025-06-03 00:20:02,815 INFO     \t Epoch 10 | average train loss: 0.0153\n",
      "2025-06-03 00:20:06,963 INFO     \t Epoch 10 | average valid loss: 1.6118\n",
      "2025-06-03 00:20:06,963 INFO     \t Epoch 10 | average valid loss: 1.6118\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 54.23ex/s, loss=0.0149]\n",
      "2025-06-03 00:20:25,402 INFO     \t Epoch 11 | average train loss: 0.0149\n",
      "2025-06-03 00:20:25,402 INFO     \t Epoch 11 | average train loss: 0.0149\n",
      "2025-06-03 00:20:29,499 INFO     \t Epoch 11 | average valid loss: 1.6168\n",
      "2025-06-03 00:20:29,499 INFO     \t Epoch 11 | average valid loss: 1.6168\n",
      "2025-06-03 00:20:34,574 INFO     \t valid MR: 25992.39 | MRR: 0.000 | H@1: 0.000 | H@3: 0.000 | H@10: 0.001\n",
      "2025-06-03 00:20:34,574 INFO     \t valid MR: 25992.39 | MRR: 0.000 | H@1: 0.000 | H@3: 0.000 | H@10: 0.001\n",
      "2025-06-03 00:20:34,578 INFO     \t Epoch 11 | average valid mmr: 0.0005\n",
      "2025-06-03 00:20:34,578 INFO     \t Epoch 11 | average valid mmr: 0.0005\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:18<00:00, 55.10ex/s, loss=0.0148]\n",
      "2025-06-03 00:20:52,730 INFO     \t Epoch 12 | average train loss: 0.0148\n",
      "2025-06-03 00:20:52,730 INFO     \t Epoch 12 | average train loss: 0.0148\n",
      "2025-06-03 00:20:56,834 INFO     \t Epoch 12 | average valid loss: 1.6194\n",
      "2025-06-03 00:20:56,834 INFO     \t Epoch 12 | average valid loss: 1.6194\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 56.94ex/s, loss=0.0147]\n",
      "2025-06-03 00:21:14,399 INFO     \t Epoch 13 | average train loss: 0.0147\n",
      "2025-06-03 00:21:14,399 INFO     \t Epoch 13 | average train loss: 0.0147\n",
      "2025-06-03 00:21:18,368 INFO     \t Epoch 13 | average valid loss: 1.6237\n",
      "2025-06-03 00:21:18,368 INFO     \t Epoch 13 | average valid loss: 1.6237\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 57.38ex/s, loss=0.0144]\n",
      "2025-06-03 00:21:35,797 INFO     \t Epoch 14 | average train loss: 0.0144\n",
      "2025-06-03 00:21:35,797 INFO     \t Epoch 14 | average train loss: 0.0144\n",
      "2025-06-03 00:21:39,678 INFO     \t Epoch 14 | average valid loss: 1.6302\n",
      "2025-06-03 00:21:39,678 INFO     \t Epoch 14 | average valid loss: 1.6302\n",
      "2025-06-03 00:21:44,330 INFO     \t valid MR: 26061.01 | MRR: 0.001 | H@1: 0.001 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:21:44,330 INFO     \t valid MR: 26061.01 | MRR: 0.001 | H@1: 0.001 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:21:44,330 INFO     \t Epoch 14 | average valid mmr: 0.0010\n",
      "2025-06-03 00:21:44,330 INFO     \t Epoch 14 | average valid mmr: 0.0010\n",
      "2025-06-03 00:21:44,335 INFO     \t Saving model at epoch 14 in ./logs/06_03\\name\\AttH_00_15_46\n",
      "2025-06-03 00:21:44,335 INFO     \t Saving model at epoch 14 in ./logs/06_03\\name\\AttH_00_15_46\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 58.30ex/s, loss=0.0144]\n",
      "2025-06-03 00:22:02,387 INFO     \t Epoch 15 | average train loss: 0.0144\n",
      "2025-06-03 00:22:02,387 INFO     \t Epoch 15 | average train loss: 0.0144\n",
      "2025-06-03 00:22:06,259 INFO     \t Epoch 15 | average valid loss: 1.6323\n",
      "2025-06-03 00:22:06,259 INFO     \t Epoch 15 | average valid loss: 1.6323\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 58.31ex/s, loss=0.0144]\n",
      "2025-06-03 00:22:23,412 INFO     \t Epoch 16 | average train loss: 0.0144\n",
      "2025-06-03 00:22:23,412 INFO     \t Epoch 16 | average train loss: 0.0144\n",
      "2025-06-03 00:22:27,371 INFO     \t Epoch 16 | average valid loss: 1.6345\n",
      "2025-06-03 00:22:27,371 INFO     \t Epoch 16 | average valid loss: 1.6345\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 58.34ex/s, loss=0.0145]\n",
      "2025-06-03 00:22:44,514 INFO     \t Epoch 17 | average train loss: 0.0145\n",
      "2025-06-03 00:22:44,514 INFO     \t Epoch 17 | average train loss: 0.0145\n",
      "2025-06-03 00:22:48,376 INFO     \t Epoch 17 | average valid loss: 1.6375\n",
      "2025-06-03 00:22:48,376 INFO     \t Epoch 17 | average valid loss: 1.6375\n",
      "2025-06-03 00:22:53,198 INFO     \t valid MR: 26115.13 | MRR: 0.001 | H@1: 0.001 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:22:53,198 INFO     \t valid MR: 26115.13 | MRR: 0.001 | H@1: 0.001 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:22:53,199 INFO     \t Epoch 17 | average valid mmr: 0.0013\n",
      "2025-06-03 00:22:53,199 INFO     \t Epoch 17 | average valid mmr: 0.0013\n",
      "2025-06-03 00:22:53,199 INFO     \t Saving model at epoch 17 in ./logs/06_03\\name\\AttH_00_15_46\n",
      "2025-06-03 00:22:53,199 INFO     \t Saving model at epoch 17 in ./logs/06_03\\name\\AttH_00_15_46\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 56.72ex/s, loss=0.0143]\n",
      "2025-06-03 00:23:11,726 INFO     \t Epoch 18 | average train loss: 0.0143\n",
      "2025-06-03 00:23:11,726 INFO     \t Epoch 18 | average train loss: 0.0143\n",
      "2025-06-03 00:23:15,840 INFO     \t Epoch 18 | average valid loss: 1.6402\n",
      "2025-06-03 00:23:15,840 INFO     \t Epoch 18 | average valid loss: 1.6402\n",
      "train loss: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 57.55ex/s, loss=0.0142]\n",
      "2025-06-03 00:23:33,221 INFO     \t Epoch 19 | average train loss: 0.0142\n",
      "2025-06-03 00:23:33,221 INFO     \t Epoch 19 | average train loss: 0.0142\n",
      "2025-06-03 00:23:37,418 INFO     \t Epoch 19 | average valid loss: 1.6432\n",
      "2025-06-03 00:23:37,418 INFO     \t Epoch 19 | average valid loss: 1.6432\n",
      "2025-06-03 00:23:37,419 INFO     \t Optimization finished\n",
      "2025-06-03 00:23:37,419 INFO     \t Optimization finished\n",
      "2025-06-03 00:23:37,420 INFO     \t Loading best model saved at epoch 17\n",
      "2025-06-03 00:23:37,420 INFO     \t Loading best model saved at epoch 17\n",
      "2025-06-03 00:23:42,498 INFO     \t valid MR: 26115.13 | MRR: 0.001 | H@1: 0.001 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:23:42,498 INFO     \t valid MR: 26115.13 | MRR: 0.001 | H@1: 0.001 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:23:47,348 INFO     \t test MR: 25857.59 | MRR: 0.000 | H@1: 0.000 | H@3: 0.001 | H@10: 0.001\n",
      "2025-06-03 00:23:47,348 INFO     \t test MR: 25857.59 | MRR: 0.000 | H@1: 0.000 | H@3: 0.001 | H@10: 0.001\n"
     ]
    }
   ],
   "source": [
    "rag.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6ca93-4feb-45fd-8756-5ebfd8892670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
