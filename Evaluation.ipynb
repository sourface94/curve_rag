{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c26715",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66900bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import llama_cpp\n",
    "import torch\n",
    "\n",
    "from curverag import utils\n",
    "from curverag.curverag import CurveRAG, DEFAULT_ENTITY_TYPES, DEFAULT_GLINER_MODEL, DEFAULT_SENTENCE_TRANSFORMER_MODEL\n",
    "from curverag.graph import KnowledgeGraph\n",
    "from curverag.atth.kg_dataset import KGDataset\n",
    "from curverag.atth.models.hyperbolic import AttH\n",
    "from curverag.eval import evaluation, queries, context, expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb821f9-2cb7-4807-b6d5-412f83e1bf0b",
   "metadata": {},
   "source": [
    "# Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9147308-1ea2-4b26-86a2-01995d94c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/nathan/Documents/projects/datasets/2WikiMultihopQA/train.json', 'rb') as f:\n",
    "    train = json.load(f)\n",
    "\n",
    "with open('/Users/nathan/Documents/projects/datasets/2WikiMultihopQA/dev.json', 'rb') as f:\n",
    "    dev = json.load(f)\n",
    "\n",
    "with open('/Users/nathan/Documents/projects/datasets/2WikiMultihopQA/test.json', 'rb') as f:\n",
    "    test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a45a70-96ea-4b27-a0c7-4f30b65913fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_id', 'type', 'question', 'context', 'supporting_facts', 'evidences', 'answer'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0641d3-d4fd-41ef-a520-f8f839e694a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are director of film Move (1970 Film) and director of film Méditerranée (1963 Film) from the same country?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b542df63-af8a-4247-a89e-b6459a93f196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a057c802-90e0-4a11-bee5-d4312efb95fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Stuart Rosenberg',\n",
       "  ['Stuart Rosenberg (August 11, 1927 – March 15, 2007) was an American film and television director whose motion pictures include \"Cool Hand Luke\" (1967), \"Voyage of the Damned\" (1976), \"The Amityville Horror\" (1979), and \"The Pope of Greenwich Village\" (1984).',\n",
       "   'He was noted for his work with actor Paul Newman.']],\n",
       " ['Méditerranée (1963 film)',\n",
       "  ['Méditerranée is a 1963 French experimental film directed by Jean-Daniel Pollet with assistance from Volker Schlöndorff.',\n",
       "   'It was written by Philippe Sollers and produced by Barbet Schroeder, with music by Antione Duhamel.',\n",
       "   'The 45 minute film is cited as one of Pollet\\'s most influential films, which according to Jonathan Rosenbaum directly influenced Jean-Luc Goddard\\'s \"Contempt\", released later the same year.',\n",
       "   'Footage for the film was shot around the Mediterranean, including at a Greek temple, a Sicilian garden, the sea, and also features a fisherman, a bullfighter, and a girl on an operating table.']],\n",
       " ['Move (1970 film)',\n",
       "  ['Move is a 1970 American comedy film starring Elliott Gould, Paula Prentiss and Geneviève Waïte, and directed by Stuart Rosenberg.',\n",
       "   'The screenplay was written by Joel Lieber and Stanley Hart, adapted from a novel by Lieber.']],\n",
       " ['Ian Barry (director)',\n",
       "  ['Ian Barry is an Australian director of film and TV.']],\n",
       " ['Peter Levin',\n",
       "  ['Peter Levin is an American director of film, television and theatre.']],\n",
       " ['Brian Johnson (special effects artist)',\n",
       "  ['Brian Johnson( born 1939 or 1940) is a British designer and director of film and television special effects.']],\n",
       " ['Rachel Feldman',\n",
       "  ['Rachel Feldman( born August 22, 1954) is an American director of film and television and screenwriter of television films.']],\n",
       " ['Hanro Smitsman',\n",
       "  ['Hanro Smitsman, born in 1967 in Breda( Netherlands), is a writer and director of film and television.']],\n",
       " ['Jean-Daniel Pollet',\n",
       "  ['Jean-Daniel Pollet (1936–2004) was a French film director and screenwriter who was most active in the 1960s and 1970s.',\n",
       "   'He was associated with two approaches to filmmaking: comedies which blended burlesque and melancholic elements, and poetic films based on texts by writers such as the French poet Francis Ponge.']],\n",
       " ['Howard W. Koch',\n",
       "  ['Howard Winchel Koch( April 11, 1916 – February 16, 2001) was an American producer and director of film and television.']]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]['context']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac072bc8-7de2-4544-a729-6b3c6c0d29ec",
   "metadata": {},
   "source": [
    "# Run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451d9c84-efe0-4304-a965-578832501932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M4 Pro) - 16383 MiB free\n",
      "llama_model_loader: loaded meta data with 27 key-value pairs and 291 tensors from ./models/Meta-Llama-3-8B-Instruct.Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Models\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                            general.license str              = llama3\n",
      "llama_model_loader: - kv   5:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   6:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   8:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q6_K\n",
      "print_info: file size   = 6.14 GiB (6.56 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128255 '<|reserved_special_token_250|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_248|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128010 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128254 '<|reserved_special_token_249|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128098 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128004 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128008 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: special tokens cache size = 256\n",
      "load: token to piece cache size = 0.8000 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 8192\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 8192\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 8B\n",
      "print_info: model params     = 8.03 B\n",
      "print_info: general.name     = Models\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128256\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128009 '<|eot_id|>'\n",
      "print_info: EOT token        = 128009 '<|eot_id|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: layer  29 assigned to device CPU\n",
      "load_tensors: layer  30 assigned to device CPU\n",
      "load_tensors: layer  31 assigned to device CPU\n",
      "load_tensors: layer  32 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q6_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 0 repeating layers to GPU\n",
      "load_tensors: offloaded 0/33 layers to GPU\n",
      "load_tensors:   CPU_Mapped model buffer size =  6282.97 MiB\n",
      ".........................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 10016\n",
      "llama_init_from_model: n_ctx_per_seq = 10016\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 500000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_pre_seq (10016) > n_ctx_train (8192) -- possible training context overflow\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M4 Pro\n",
      "ggml_metal_init: picking default device: Apple M4 Pro\n",
      "ggml_metal_load_library: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M4 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 17179.89 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x107cc6540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                                0x116dd28e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x1316bf440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                                0x116de58b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x3b628e2c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                                0x116dda400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x316b86dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                                0x107cf1340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x135faf340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x3b628d1e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x3b628d4a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x13175f770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x116dda6c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x13176b470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x116df6c90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x116df7180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x116df78a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x131010e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x316b89030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x131011930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x107cb4250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x131011e70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x107ca9180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x135fb0e20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x107ce4c10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x135fb1290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x1310123b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x135fb1550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x135fb19c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x316b892f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x131012670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x116df7d40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x316b895b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x30ed8c8e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x135fb1e30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x316b89870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x30ed8cba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x107cef7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x135fb20f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x116df81e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x116df84a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x3adb3ccf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x3b628d760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x131012930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x316b89b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x3b628e610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x3adb3d050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x131012f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x110d06010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x110d12490 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x316b89df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x110d25ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x1310131c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x135fb2c90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x131013480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x135fb2f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x131013740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x131013a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x116df8910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x30ed8cf00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x131013cc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x316b8a0b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x3b628e8d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x316b8a370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x116df8ca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x30ed8d1c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x3b628eb90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x3adb3d310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x30ed8d480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x3adb3d860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x3adb3db20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x135fb3570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x3b628f0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x3b628f3a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x3b628f660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x131013f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x316b8a8c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x116df92c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x110d29560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x110d10560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x131014240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x131014500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x110d2a230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x135fb3ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x1310147c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x135fb41b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x131014a80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x116df9580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x30ed8d740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x3adb3dde0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x131014d40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x135fb47d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x316b8ab80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x3adb3e0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x135fb4df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x135fb5260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x135fb56d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x110d28a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x116dfa0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x110d251a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x131012bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x110d26dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x110d1e500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x135fb5990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x30ed8da00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x116dfa720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x30ed8dcc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x116dfac70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x316b8ae40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x135fb5fb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x316b8b100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x116dfaf30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x131015000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x135fb65d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x135fb6a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x1310152c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x316b8b3c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x135fb6d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x131015580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x135fb7320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x3adb3e360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x116dfb730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x116dfb9f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x3adb3e620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x110db65c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x110dbd230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x116dfbe90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x316b8b680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x131015840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x110d18320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x110d0ce90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x116dfc150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x131015b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x131015dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x135fb7790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x116dfc5f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x135fb7c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x116dfc8b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x316b8b940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x135fb8220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x131016080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x107cf7100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x135fb8690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x131016340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x107cd96f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x135fb8950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x135fb8dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x316b8bc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x135fb9080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x316b8bec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x1310169f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x135fb94f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x116dfd0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x30ed8df80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x3adb3e8e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x107cd64f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x107cd69f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x116dfd3a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x135fb9cc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x30ed8e240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x1310170a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x30ed8e500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x135fba2e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x3adb3eba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x30ed8e7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x131017600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x1310178c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x316b8c180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x316b8c440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x3b628f920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x30ed8ea80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x30ed8ed40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x107cd6ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x107cd73f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x135fbac60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x3adb3ee60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x30ed8f000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x3adb3f120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x107cd78f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x3b628fbe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x107cd7df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x131017fa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x107cd82f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x3b628fea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x3b6290160 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x131018260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x131018660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x107cd87f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x135fbb0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x116dfd9c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x116dfe010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x135fbb390 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x3b6290420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x131018e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x116dfe660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x116dfebb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x107cd8cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x135fbb800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x135fbbc70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x135fbc0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x107cd91f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x135fbc550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x116dff400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x135fbc9c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x135fbce30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x1310193b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x131019670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x3b62906e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x3b62909a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x30ed8f2c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x116dff950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x131019c90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x131019f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x135fbd2a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x116dffc10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x31a304080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x107cdfb90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x110db95d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x110dc7f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x30ed8f580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x13101a7d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x135fbd8c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x31a3044f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x316b8c700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x316b8c9c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x30ed8f840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x316b8cc80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x31a3047b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x30ed8fb00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x30ed8fdc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x110de4c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x110dee8d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x13101ac40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x13101b190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x135fbdd30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x13101b6e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x13101bc30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x31a304dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x135fbe1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x31a305090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x31a305350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x135fbe7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x13101c330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x110df6e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x31a3057c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x30ed90080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x135fbec30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x31a305c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x13101c880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x135fbeef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x13101ccf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x110df8940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x110de5860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x31a3060a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x110deaa70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x13101d3f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x13101d890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x31a306510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x31a306980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x110debc30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x31a306fa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x31a307410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x110dc1850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x13101db50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x13101dff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x135fbf1b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x13101e490 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x13101e930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x31a3076d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x3b6290c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x135fbf470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x31a307b40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x135fbf8e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x30ed90340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x316b8cf40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x3b6290f20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x31a308230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x13101edd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x3adb3f3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x3adb3f6a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x30ed90600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x316b8d200 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init: kv_size = 10016, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1252.00 MiB\n",
      "llama_init_from_model: KV self size  = 1252.00 MiB, K (f16):  626.00 MiB, V (f16):  626.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   677.57 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 514 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | SME = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128009', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.pre': 'llama-bpe', 'tokenizer.ggml.model': 'gpt2', 'llama.vocab_size': '128256', 'llama.attention.head_count_kv': '8', 'llama.context_length': '8192', 'llama.attention.head_count': '32', 'general.file_type': '18', 'general.size_label': '8.0B', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.license': 'llama3', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.architecture': 'llama', 'llama.rope.dimension_count': '128', 'llama.rope.freq_base': '500000.000000', 'general.type': 'model', 'general.name': 'Models'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "max_tokens = 10000\n",
    "n_ctx=10000\n",
    "\n",
    "llm, outlines_model = utils.load_model(\n",
    "    llm_model_path=\"./models/Meta-Llama-3-8B-Instruct.Q6_K.gguf\",\n",
    "    tokenizer=llama_cpp.llama_tokenizer.LlamaHFTokenizer.from_pretrained(\"unsloth/Llama-3.2-1B-Instruct\"),\n",
    "    n_ctx=n_ctx,\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886c4eb3-ce85-4209-aea9-f8322244a878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ff22fa4fa4471ba026a2277cf2c10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathan/Documents/projects/curve_rag/.venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "entity_types = ['people', 'locations', 'entities', 'movies', 'directors']\n",
    "rag = CurveRAG(\n",
    "    llm,\n",
    "    outlines_model,\n",
    "    entity_types,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453c89d8-f94d-4246-a089-26e9616020b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs = []\n",
    "for d in train[0]['context']:\n",
    "    d_ = str(d).replace('[', '').replace(']', '. ').replace('\\'', '')\n",
    "    new_docs.append(d_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0271be-300b-45f8-a47f-ce522a451386",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs = []\n",
    "for d in train:\n",
    "    d_ = str(d['context']).replace('[', '').replace(']', '. ').replace('\\'', '')\n",
    "    new_docs.append(d_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8929d30-d5d3-4536-8c0c-6d8fb47303e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Falcon Takes Over, The Falcon Takes Over( also known as The Falcon Steps Out), is a 1942 black- and- white mystery film directed by Irving Reis., The B film was the third, following\" The Gay Falcon\" and\" A Date with the Falcon\"( 1941), to star George Sanders as the character Gay Lawrence, a gentleman detective known by the sobriquet the Falcon.. . , The Falcon Strikes Back, The Falcon Strikes Back( The Falcon Comes Back) is a 1943 American crime film directed by Edward Dmytryk and stars Tom Conway as the title character, the amateur sleuth, the Falcon., Supporting roles are filled by Harriet Hilliard, Jane Randolph, Edgar Kennedy, with Cliff Edwards filling in for Allen Jenkins as the Falcon\\\\s sidekick,\" Goldie\" Locke., It is the sixth film in the Falcon series and the second for Conway, reprising the role that his brother, George Sanders had initiated.. . , Vatroslav Mimica, Vatroslav Mimica( born 25 June 1923) is a Croatian film director and screenwriter., Born in Omiš, Mimica had enrolled at the University of Zagreb School of Medicine before the outbreak of World War II., In 1942 he joined Young Communist League of Yugoslavia( SKOJ) and in 1943 he went on to join the Yugoslav Partisans, becoming a member of their medical units., After the war Mimica wrote literary and film reviews, and his career in filmmaking began in 1950 when he became the director of the Jadran Film production studio., He had his directorial and screenwriting debut in the 1952 Yugoslav film\" In the Storm\"( Croatian:\" U oluji\") which starred Veljko Bulajić, Mia Oremović and Antun Nalis., In the 1950s Mimica worked as a director and writer on a number of critically acclaimed animated films and became a prominent member of the Zagreb School of Animated Films( his 1958 animated short film\" The LonerSamac\") was awarded the Venice Grand Prix), along with authors such as Vlado Kristl and Academy Award- winning Dušan Vukotić., In the 1960s Mimica moved away from animation( his last animated film was 1971 film\" The FiremenVatrogasci\")) and turned to directing feature films, starting with the 1961 Yugoslav- Italian film\" Suleiman the Conqueror\"( Italian:\" Solimano il conquistatore\") starring Edmund Purdom and Giorgia Moll., His 1965 film\" Prometheus of the IslandPrometej s otoka Viševice\") won the Big Golden Arena for Best Film at the 1965 Pula Film Festival and earned Mimica a runner- up Silver Arena award for Best Director., It was also entered into the 4th Moscow International Film Festival winning a Special Diploma., The following year his 1966 film\" Monday or TuesdayPonedjeljak ili utorak\") also won the Big Golden Arena for Best Film and Mimica won the Golden Arena for Best Director., Mimica made several other films through the 1970s, most notably the period films\" Anno Domini 1573( Peasant revolt of 1573) Seljačka buna 1573.\" in Croatian- depicting the 16th century Croatian- Slovenian peasant revolt, and\" The FalconBanović Strahinja\"), set in 14th century Serbia, before retiring from filmmaking in 1981., His son Sergio Mimica- Gezzan is an American film and television director.. . , The Falcon and the Co-eds, The Falcon and the Co-eds is a 1943 film under the direction of William Clemens, and produced by Maurice Geraghty, the same team that had worked on\" The Falcon in Danger\"( 1943) and would stay together for the next film in the Falcon series., \" The Falcon and the Co-eds\" was the seventh of 16 in the Falcon series., The story and screenplay was by Ardel Wray, a frequent collaborator with Val Lewton in his RKO horror series, who added supernatural elements to the proceedings., As he had in the past three Falcon films, Tom Conway played the suave amateur sleuth, this time backed up by a bevy of young starlets, including Jean Brooks, Rita Corday and Amelita Ward.. . , Martin Frič, Martin Frič( 29 March 1902 – 26 August 1968) was a Czech film director, screenwriter and actor., He had more than 100 directing credits between 1929 and 1968, including feature films, shorts and documentary films., Throughout his life, Frič struggled with alcoholism., On the day of the Warsaw Pact invasion of Czechoslovakia in 1968, he attempted suicide, after battling cancer., He died in the hospital five days later.. . , \"The Falcons Adventure\", \"The Falcons Adventure is a 1946 film which was the 13th of sixteen films about The Falcon and the final film of RKOs Falcon series starring Tom Conway.\", It was directed by William Berke, who had served as producer for the previous entry in the series, 1946\\\\s\" The Falcon\\\\s Alibi\".. . , \"The Falcons Alibi\", \"The Falcons Alibi is a 1946 American mystery film directed by Ray McCarey and starring Tom Conway, Rita Corday and Vince Barnett.\", It was the ninth film featuring Conway as The Falcon., After the following film,\" The Falcon\\\\s Adventure\", the series was ended due to declining popularity.. . , Valentin the Good, Valentin the Good is a 1942 Czech comedy film directed by Martin Frič.. . , The Falcon (film), Banović Strahinja( Serbian Cyrillic:\" Бановић Страхиња\", released internationally as The Falcon) is a 1981 Yugoslavian- German adventure film written and directed by Vatroslav Mimica based on Strahinja Banović, a hero of Serbian epic poetry., It entered the section\" Officina Veneziana\" at the 38th Venice International Film Festival.. . , The Falcon Out West, The Falcon Out West( aka The Falcon in Texas) is a 1944 American mystery film directed by William Clemens and starring Tom Conway, Joan Barclay and Barbara Hale., \"The film was part of RKOs The Falcon series of detective films, this time, a murder set in Texas.\". . . '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25dfda31-3030-44da-b983-0d17a279e1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docs = [\\n    \"The patient was diagnosed with type 2 diabetes mellitus and prescribed metformin 500mg twice daily.\",\\n    \"MRI scan revealed a small lesion in the left temporal lobe suggestive of low-grade glioma.\",\\n    \"Administer 5mg of lorazepam intravenously for acute seizure management.\",\\n    \"Blood tests showed elevated ALT and AST levels, indicating possible liver inflammation.\",\\n    \"The subject reported chronic lower back pain, managed with physical therapy and NSAIDs.\",\\n    \"CT angiography confirmed the presence of a pulmonary embolism in the right lower lobe.\",\\n    \"The patient underwent coronary artery bypass graft surgery without complications.\",\\n    \"Routine vaccination included MMR, tetanus, and influenza immunizations.\",\\n    \"Histopathology indicated ductal carcinoma in situ (DCIS) in the breast biopsy sample.\",\\n    \"The child presented with a persistent cough and fever, diagnosed as streptococcal pharyngitis.\"\\n]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''docs = [\n",
    "    \"The patient was diagnosed with type 2 diabetes mellitus and prescribed metformin 500mg twice daily.\",\n",
    "    \"MRI scan revealed a small lesion in the left temporal lobe suggestive of low-grade glioma.\",\n",
    "    \"Administer 5mg of lorazepam intravenously for acute seizure management.\",\n",
    "    \"Blood tests showed elevated ALT and AST levels, indicating possible liver inflammation.\",\n",
    "    \"The subject reported chronic lower back pain, managed with physical therapy and NSAIDs.\",\n",
    "    \"CT angiography confirmed the presence of a pulmonary embolism in the right lower lobe.\",\n",
    "    \"The patient underwent coronary artery bypass graft surgery without complications.\",\n",
    "    \"Routine vaccination included MMR, tetanus, and influenza immunizations.\",\n",
    "    \"Histopathology indicated ductal carcinoma in situ (DCIS) in the breast biopsy sample.\",\n",
    "    \"The child presented with a persistent cough and fever, diagnosed as streptococcal pharyngitis.\"\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83836ea2-4da5-4853-8fe1-b0ddbdd5bb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docs = [\\n    context,\\n    \"The patient was diagnosed with type 2 diabetes mellitus and prescribed metformin 500mg twice daily.\",\\n    \"MRI scan revealed a small lesion in the left temporal lobe suggestive of low-grade glioma.\",\\n]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''docs = [\n",
    "    context,\n",
    "    \"The patient was diagnosed with type 2 diabetes mellitus and prescribed metformin 500mg twice daily.\",\n",
    "    \"MRI scan revealed a small lesion in the left temporal lobe suggestive of low-grade glioma.\",\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3cab56-c589-481e-a615-fc8530546977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]Llama.generate: 2 prefix-match hit, remaining 1266 prompt tokens to eval\n"
     ]
    }
   ],
   "source": [
    "rag.fit(new_docs[:100], dataset_name='movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bce927bb-c29e-4545-9408-7576ea01fc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Node(id=1, name='Stuart Rosenberg', description='American film and television director', alias=['Stuart Rosenberg'], additional_information=['August 11, 1927 – March 15, 2007']),\n",
       " Node(id=2, name='Paul Newman', description='Actor', alias=[], additional_information=[]),\n",
       " Node(id=3, name='Cool Hand Luke', description='Film', alias=[], additional_information=[]),\n",
       " Node(id=4, name='Voyage of the Damned', description='Film', alias=[], additional_information=[]),\n",
       " Node(id=5, name='The Amityville Horror', description='Film', alias=[], additional_information=[]),\n",
       " Node(id=6, name='The Pope of Greenwich Village', description='Film', alias=[], additional_information=[]),\n",
       " Node(id=7, name='Jean-Daniel Pollet', description='French film director', alias=[], additional_information=[]),\n",
       " Node(id=8, name='Volker Schlöndorff', description='German film director', alias=[], additional_information=[]),\n",
       " Node(id=9, name='Philippe Sollers', description='French writer', alias=[], additional_information=[]),\n",
       " Node(id=10, name='Barbet Schroeder', description='French film producer', alias=[], additional_information=[]),\n",
       " Node(id=11, name='Antione Duhamel', description='French composer', alias=[], additional_information=[]),\n",
       " Node(id=12, name='Jean-Luc Godard', description='French film director', alias=[], additional_information=[]),\n",
       " Node(id=13, name='Méditerranée', description='1963 French experimental film', alias=[], additional_information=[]),\n",
       " Node(id=14, name='Contempt', description='1963 French film', alias=[], additional_information=[]),\n",
       " Node(id=15, name='Move', description='1970 American comedy film', alias=[], additional_information=['1970 film', 'American comedy film']),\n",
       " Node(id=16, name='Elliott Gould', description='Actor', alias=[], additional_information=[]),\n",
       " Node(id=17, name='Paula Prentiss', description='Actress', alias=[], additional_information=[]),\n",
       " Node(id=18, name='Geneviève Waïte', description='Actress', alias=[], additional_information=[]),\n",
       " Node(id=20, name='Joel Lieber', description='Screenwriter', alias=[], additional_information=[]),\n",
       " Node(id=21, name='Stanley Hart', description='Screenwriter', alias=[], additional_information=[]),\n",
       " Node(id=19, name='Ian Barry', description='Australian director of film and TV', alias=[], additional_information=[]),\n",
       " Node(id=22, name='Peter Levin', description='American director of film, television and theatre', alias=[], additional_information=[]),\n",
       " Node(id=23, name='American director', description='Director of film, television and theatre', alias=[], additional_information=[]),\n",
       " Node(id=24, name='Brian Johnson', description='British designer and director of film and television special effects', alias=['Brian Johnson'], additional_information=['born 1939 or 1940']),\n",
       " Node(id=25, name='Rachel Feldman', description='American director of film and television and screenwriter of television films', alias=[], additional_information=['born August 22, 1954']),\n",
       " Node(id=26, name='Hanro Smitsman', description='Writer and director of film and television', alias=['Hanro Smitsman'], additional_information=['born in 1967 in Breda, Netherlands']),\n",
       " Node(id=27, name='Breda', description='City in the Netherlands', alias=[], additional_information=['Netherlands']),\n",
       " Node(id=29, name='Francis Ponge', description='French poet', alias=[], additional_information=[]),\n",
       " Node(id=28, name='Howard W. Koch', description='American producer and director of film and television', alias=[], additional_information=['April 11, 1916 – February 16, 2001'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53089ce6-052f-42b9-8c77-a44ea84d6423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source=1, target=3, name='Directed', is_directed=True, description='Directed the film', notes=[]),\n",
       " Edge(source=1, target=4, name='Directed', is_directed=True, description='Directed the film', notes=[]),\n",
       " Edge(source=1, target=5, name='Directed', is_directed=True, description='Directed the film', notes=[]),\n",
       " Edge(source=1, target=6, name='Directed', is_directed=True, description='Directed the film', notes=[]),\n",
       " Edge(source=1, target=2, name='Worked with', is_directed=True, description='Worked with the actor', notes=[]),\n",
       " Edge(source=7, target=13, name='Directed', is_directed=True, description='Directed the film', notes=[]),\n",
       " Edge(source=7, target=14, name='Influenced', is_directed=True, description='Influenced the film', notes=[]),\n",
       " Edge(source=8, target=13, name='Assisted', is_directed=True, description='Assisted the director', notes=[]),\n",
       " Edge(source=9, target=13, name='Wrote', is_directed=True, description='Wrote the script', notes=[]),\n",
       " Edge(source=10, target=13, name='Produced', is_directed=True, description='Produced the film', notes=[]),\n",
       " Edge(source=11, target=13, name='Composed', is_directed=True, description='Composed the music', notes=[]),\n",
       " Edge(source=12, target=14, name='Influenced', is_directed=True, description='Influenced the film', notes=[]),\n",
       " Edge(source=1, target=15, name='Directed', is_directed=True, description='Directed the film', notes=[]),\n",
       " Edge(source=1, target=16, name='Worked with', is_directed=True, description='Worked with the actor', notes=[]),\n",
       " Edge(source=1, target=17, name='Worked with', is_directed=True, description='Worked with the actress', notes=[]),\n",
       " Edge(source=1, target=18, name='Worked with', is_directed=True, description='Worked with the actress', notes=[]),\n",
       " Edge(source=20, target=15, name='Wrote', is_directed=True, description='Wrote the screenplay', notes=[]),\n",
       " Edge(source=21, target=15, name='Wrote', is_directed=True, description='Wrote the screenplay', notes=[]),\n",
       " Edge(source=1, target=19, name='Directed', is_directed=True, description='Directed the film', notes=[]),\n",
       " Edge(source=22, target=23, name='Is', is_directed=True, description='Is a', notes=[]),\n",
       " Edge(source=25, target=23, name='Is', is_directed=True, description='Is a', notes=[]),\n",
       " Edge(source=26, target=27, name='Born in', is_directed=True, description='Born in the city', notes=[]),\n",
       " Edge(source=7, target=29, name='Worked with', is_directed=True, description='Worked with the poet', notes=[])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68ba94de-bf87-4c90-9036-09d8358d30b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How old is Jack?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d523f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are director of film Move (1970 Film) and director of film Méditerranée (1963 Film) from the same country?\n",
      "entities ['Move', 'Méditerranée']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9dc277525142e0ba4c559583804fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[np.int64(12), np.int64(14)]]\n",
      "node_ids [tensor([4, 2, 6]), tensor([4, 3, 7])]\n",
      "node_ids [4, 2, 6, 4, 3, 7]\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "\n",
      "You are a helpful assistant analyzing the given input data to provide an helpful response to the user query.\n",
      "\n",
      "# USER QUERY\n",
      "Are director of film Move (1970 Film) and director of film Méditerranée (1963 Film) from the same country?\n",
      "\n",
      "# Context:\n",
      "KnowledgeGraph Overview\n",
      "  There are 7 entities and 1 relationships in this graph.\n",
      "\n",
      "Entities in the graph:\n",
      "  • 'Paul Newman':\n",
      "      The entity has the following description: Actor\n",
      "  • 'Cool Hand Luke':\n",
      "      The entity has the following description: Film\n",
      "  • 'Voyage of the Damned':\n",
      "      The entity has the following description: Film\n",
      "  • 'The Pope of Greenwich Village':\n",
      "      The entity has the following description: Film\n",
      "  • 'Jean-Daniel Pollet':\n",
      "      The entity has the following description: French film director\n",
      "  • 'Méditerranée':\n",
      "      The entity has the following description: 1963 French experimental film\n",
      "  • 'Move':\n",
      "      The entity has the following description: 1970 American comedy film\n",
      "\n",
      "Relationships between nodes:\n",
      "  • There is a directed relationship from 'Jean-Daniel Pollet' to 'Méditerranée' called 'Directed'.\n",
      "      The relationship is described as: Directed the film\n",
      "      The relationship has the following notes: \n",
      "\n",
      "\n",
      "\n",
      "# INSTRUCTIONS\n",
      "Your goal is to provide a response to the user query using the relevant information in the input data:\n",
      "- the \"Entities\" and \"Relationships\" tables contain high-level information. Use these tables to identify the most important entities and relationships to respond to the query.\n",
      "- the \"Sources\" list contains raw text sources to help answer the query. It may contain noisy data, so pay attention when analyzing it.\n",
      "\n",
      "Follow these steps:\n",
      "1. Read and understand the user query.\n",
      "2. Look at the \"Entities\" and \"Relationships\" tables to get a general sense of the data and understand which information is the most relevant to answer the query.\n",
      "3. Carefully analyze all the \"Sources\" to get more detailed information. Information could be scattered across several sources, use the identified relevant entities and relationships to guide yourself through the analysis of the sources.\n",
      "4. While you write the response, you must include inline references to the all the sources you are using by appending `[<source_id>]` at the end of each sentence, where `source_id` is the corresponding source ID from the \"Sources\" list.\n",
      "5. Write the response to the user query - which must include the inline references - based on the information you have gathered. Be very concise and answer the user query directly. If the response cannot be inferred from the input data, just say no relevant information was found. Do not make anything up or add unrelevant information.\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    9934.85 ms\n",
      "llama_perf_context_print: prompt eval time =   16438.24 ms /   566 tokens (   29.04 ms per token,    34.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =   44506.09 ms /    99 runs   (  449.56 ms per token,     2.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   61351.46 ms /   665 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the information provided, it can be inferred that Jean-Daniel Pollet directed the film 'Méditerranée' [1]. However, there is no information about Jean-Daniel Pollet directing a film called 'Move' [2]. Therefore, it can be concluded that the director of the film 'Move' and the director of the film 'Méditerranée' are not the same. [1: The entity has the following description: French film director] [2\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Question:', train[0]['question'])\n",
    "resp = rag.query(train[0]['question'])\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff34e6b7-452f-4e0c-ba0d-052e5832405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What gender is Jill?Give me the character arc of Sam\n",
      "entities ['Jill', 'Sam']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd1d8ab1d7e4ca7ae48e0aab9ba1fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[np.int64(1), np.int64(2)]]\n",
      "node_ids [tensor([9, 7]), tensor([4, 0, 5])]\n",
      "node_ids [9, 7, 4, 0, 5]\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "\n",
      "You are a helpful assistant analyzing the given input data to provide an helpful response to the user query.\n",
      "\n",
      "# USER QUERY\n",
      "What gender is Jill?Give me the character arc of Sam\n",
      "\n",
      "# Context:\n",
      "KnowledgeGraph Overview\n",
      "  There are 6 entities and 7 relationships in this graph.\n",
      "\n",
      "Entities in the graph:\n",
      "  • 'Jill':\n",
      "      The entity has the following description: Jill is an adult sibling of Jack.\n",
      "      It can also be referred to as: Jill\n",
      "      It has the following additional information: 45 years old, twins with Jack\n",
      "  • 'Sam':\n",
      "      The entity has the following description: Sam is a friend of Jack and Jill.\n",
      "      It can also be referred to as: Sam\n",
      "      It has the following additional information: single for a long time, found love with friend\n",
      "  • 'Friend':\n",
      "      The entity has the following description: The friend of Jack and Jill who is a good match for Sam.\n",
      "      It can also be referred to as: Friend\n",
      "      It has the following additional information: helped Sam find love\n",
      "  • 'Romania':\n",
      "      The entity has the following description: A country where Sam and their friend moved to.\n",
      "      It can also be referred to as: Romania\n",
      "      It has the following additional information: home to a massive Castle\n",
      "  • 'Patient':\n",
      "      The entity has the following description: A person who was diagnosed with type 2 diabetes mellitus.\n",
      "      It can also be referred to as: Patient\n",
      "      It has the following additional information: diagnosed with type 2 diabetes mellitus\n",
      "  • 'Metformin':\n",
      "      The entity has the following description: A medication used to treat type 2 diabetes mellitus.\n",
      "      It can also be referred to as: Metformin\n",
      "      It has the following additional information: prescribed 500mg twice daily\n",
      "\n",
      "Relationships between nodes:\n",
      "  • There is a directed relationship from 'Jill' to 'Sam' called 'Friend'.\n",
      "      The relationship is described as: Jill and Sam are friends.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Sam' to 'Friend' called 'Matchmaker'.\n",
      "      The relationship is described as: Sam found love with the help of Jack and Jill's friend.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Sam' to 'Romania' called 'MovedTo'.\n",
      "      The relationship is described as: Sam and their friend moved to Romania.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Patient' to 'Metformin' called 'Prescribed'.\n",
      "      The relationship is described as: The patient was prescribed metformin 500mg twice daily.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Jill' to 'Sam' called 'LocatedIn'.\n",
      "      The relationship is described as: The left temporal lobe is located in the brain.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Sam' to 'Friend' called 'TypeOf'.\n",
      "      The relationship is described as: Low-grade glioma is a type of glioma.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Friend' to 'Romania' called 'TypeOf'.\n",
      "      The relationship is described as: Glioma is a type of brain tumor.\n",
      "      The relationship has the following notes: \n",
      "\n",
      "\n",
      "\n",
      "# INSTRUCTIONS\n",
      "Your goal is to provide a response to the user query using the relevant information in the input data:\n",
      "- the \"Entities\" and \"Relationships\" tables contain high-level information. Use these tables to identify the most important entities and relationships to respond to the query.\n",
      "- the \"Sources\" list contains raw text sources to help answer the query. It may contain noisy data, so pay attention when analyzing it.\n",
      "\n",
      "Follow these steps:\n",
      "1. Read and understand the user query.\n",
      "2. Look at the \"Entities\" and \"Relationships\" tables to get a general sense of the data and understand which information is the most relevant to answer the query.\n",
      "3. Carefully analyze all the \"Sources\" to get more detailed information. Information could be scattered across several sources, use the identified relevant entities and relationships to guide yourself through the analysis of the sources.\n",
      "4. While you write the response, you must include inline references to the all the sources you are using by appending `[<source_id>]` at the end of each sentence, where `source_id` is the corresponding source ID from the \"Sources\" list.\n",
      "5. Write the response to the user query - which must include the inline references - based on the information you have gathered. Be very concise and answer the user query directly. If the response cannot be inferred from the input data, just say no relevant information was found. Do not make anything up or add unrelevant information.\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 1005 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    9163.97 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    9254.43 ms /   100 runs   (   92.54 ms per token,    10.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    9668.53 ms /   101 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jill is an adult sibling of Jack. As for the character arc of Sam, Sam is a friend of Jack and Jill, and they helped Sam find love. Sam then moved to Romania with their friend [1]. Sam found love in Romania, marking a significant change in their life [2].\\n\\nReferences:\\n[1] Entity: Romania\\n[2] Relationship: Sam moved to Romania with their friend\\n\\nNote: The answer is based on the information provided in the input data, and it is'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Question:', queries[1])\n",
    "resp = rag.query(queries[1])\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0aa48d3-da9f-4ec1-b825-65c5b0c98539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What location is the story set in\n",
      "entities []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5743d57224874fe3bee85c105db393a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n",
      "node_ids []\n",
      "node_ids []\n",
      "\n",
      "You are a helpful assistant analyzing the given input data to provide an helpful response to the user query.\n",
      "\n",
      "# USER QUERY\n",
      "What location is the story set in\n",
      "\n",
      "# Context:\n",
      "KnowledgeGraph Overview\n",
      "  There are 0 entities and 0 relationships in this graph.\n",
      "\n",
      "Entities in the graph:\n",
      "\n",
      "Relationships between nodes:\n",
      "\n",
      "\n",
      "\n",
      "# INSTRUCTIONS\n",
      "Your goal is to provide a response to the user query using the relevant information in the input data:\n",
      "- the \"Entities\" and \"Relationships\" tables contain high-level information. Use these tables to identify the most important entities and relationships to respond to the query.\n",
      "- the \"Sources\" list contains raw text sources to help answer the query. It may contain noisy data, so pay attention when analyzing it.\n",
      "\n",
      "Follow these steps:\n",
      "1. Read and understand the user query.\n",
      "2. Look at the \"Entities\" and \"Relationships\" tables to get a general sense of the data and understand which information is the most relevant to answer the query.\n",
      "3. Carefully analyze all the \"Sources\" to get more detailed information. Information could be scattered across several sources, use the identified relevant entities and relationships to guide yourself through the analysis of the sources.\n",
      "4. While you write the response, you must include inline references to the all the sources you are using by appending `[<source_id>]` at the end of each sentence, where `source_id` is the corresponding source ID from the \"Sources\" list.\n",
      "5. Write the response to the user query - which must include the inline references - based on the information you have gathered. Be very concise and answer the user query directly. If the response cannot be inferred from the input data, just say no relevant information was found. Do not make anything up or add unrelevant information.\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 28 prefix-match hit, remaining 333 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    9163.97 ms\n",
      "llama_perf_context_print: prompt eval time =    3022.72 ms /   333 tokens (    9.08 ms per token,   110.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4559.04 ms /    99 runs   (   46.05 ms per token,    21.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    7756.66 ms /   432 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the given input data, no location is mentioned in the data. Therefore, it is not possible to determine the location of the story based on the provided information. [1]\\n\\nSource: [1] - There is no source ID provided in the input data. \\n\\nNote: I've followed the instructions and tried my best to provide a helpful response to the user query. Please let me know if I can improve anything. \\n\\nPlease let me know if the response is accurate and if there's\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Question:', queries[2])\n",
    "resp = rag.query(queries[2])\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcc44cee-8920-42f7-b6db-75f19e7bcbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What location is the story set in\n",
      "entities []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b68aaa6e0143de9973adb360001271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[]]\n",
      "node_ids []\n",
      "node_ids []\n",
      "\n",
      "You are a helpful assistant analyzing the given input data to provide an helpful response to the user query.\n",
      "\n",
      "# USER QUERY\n",
      "What location is the story set in\n",
      "\n",
      "# Context:\n",
      "KnowledgeGraph Overview\n",
      "  There are 0 entities and 0 relationships in this graph.\n",
      "\n",
      "Entities in the graph:\n",
      "\n",
      "Relationships between nodes:\n",
      "\n",
      "\n",
      "\n",
      "# INSTRUCTIONS\n",
      "Your goal is to provide a response to the user query using the relevant information in the input data:\n",
      "- the \"Entities\" and \"Relationships\" tables contain high-level information. Use these tables to identify the most important entities and relationships to respond to the query.\n",
      "- the \"Sources\" list contains raw text sources to help answer the query. It may contain noisy data, so pay attention when analyzing it.\n",
      "\n",
      "Follow these steps:\n",
      "1. Read and understand the user query.\n",
      "2. Look at the \"Entities\" and \"Relationships\" tables to get a general sense of the data and understand which information is the most relevant to answer the query.\n",
      "3. Carefully analyze all the \"Sources\" to get more detailed information. Information could be scattered across several sources, use the identified relevant entities and relationships to guide yourself through the analysis of the sources.\n",
      "4. While you write the response, you must include inline references to the all the sources you are using by appending `[<source_id>]` at the end of each sentence, where `source_id` is the corresponding source ID from the \"Sources\" list.\n",
      "5. Write the response to the user query - which must include the inline references - based on the information you have gathered. Be very concise and answer the user query directly. If the response cannot be inferred from the input data, just say no relevant information was found. Do not make anything up or add unrelevant information.\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 27 prefix-match hit, remaining 334 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    9163.97 ms\n",
      "llama_perf_context_print: prompt eval time =    3546.62 ms /   334 tokens (   10.62 ms per token,    94.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4649.51 ms /    99 runs   (   46.96 ms per token,    21.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    8388.49 ms /   433 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The story is set in [1]. [2] This information is based on the given input data. No other information is available for this query. If more information is provided, it could be possible to provide a more detailed answer.\\n\\nPlease provide more information about the story, as the current input data does not contain enough information to answer the query accurately. \\n\\n[1] <Source ID>\\n[2] <Source ID> \\n\\nPlease provide the Source IDs and the actual source text. I'll\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Question:', queries[3])\n",
    "resp = rag.query(queries[3])\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c779e49f-ded8-4f92-833c-8216afff1918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Tell me how old Jack is, what the gender of Jill is, and then give me the character arcs of Sam and where the stoty is set\n",
      "entities ['Jack', 'Jill', 'Sam']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f72c3f410c42e08a404b36d3643b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[np.int64(0), np.int64(1), np.int64(2)]]\n",
      "node_ids [tensor([4, 2]), tensor([9, 7]), tensor([4, 0, 5])]\n",
      "node_ids [4, 2, 9, 7, 4, 0, 5]\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "***************************************!!******************************\n",
      "\n",
      "You are a helpful assistant analyzing the given input data to provide an helpful response to the user query.\n",
      "\n",
      "# USER QUERY\n",
      "Tell me how old Jack is, what the gender of Jill is, and then give me the character arcs of Sam and where the stoty is set\n",
      "\n",
      "# Context:\n",
      "KnowledgeGraph Overview\n",
      "  There are 7 entities and 10 relationships in this graph.\n",
      "\n",
      "Entities in the graph:\n",
      "  • 'Jack':\n",
      "      The entity has the following description: Jack is an adult sibling of Jill.\n",
      "      It can also be referred to as: Jack\n",
      "      It has the following additional information: 45 years old, twins with Jill\n",
      "  • 'Jill':\n",
      "      The entity has the following description: Jill is an adult sibling of Jack.\n",
      "      It can also be referred to as: Jill\n",
      "      It has the following additional information: 45 years old, twins with Jack\n",
      "  • 'Sam':\n",
      "      The entity has the following description: Sam is a friend of Jack and Jill.\n",
      "      It can also be referred to as: Sam\n",
      "      It has the following additional information: single for a long time, found love with friend\n",
      "  • 'Friend':\n",
      "      The entity has the following description: The friend of Jack and Jill who is a good match for Sam.\n",
      "      It can also be referred to as: Friend\n",
      "      It has the following additional information: helped Sam find love\n",
      "  • 'Romania':\n",
      "      The entity has the following description: A country where Sam and their friend moved to.\n",
      "      It can also be referred to as: Romania\n",
      "      It has the following additional information: home to a massive Castle\n",
      "  • 'Patient':\n",
      "      The entity has the following description: A person who was diagnosed with type 2 diabetes mellitus.\n",
      "      It can also be referred to as: Patient\n",
      "      It has the following additional information: diagnosed with type 2 diabetes mellitus\n",
      "  • 'Metformin':\n",
      "      The entity has the following description: A medication used to treat type 2 diabetes mellitus.\n",
      "      It can also be referred to as: Metformin\n",
      "      It has the following additional information: prescribed 500mg twice daily\n",
      "\n",
      "Relationships between nodes:\n",
      "  • There is a directed relationship from 'Jack' to 'Jill' called 'Sibling'.\n",
      "      The relationship is described as: Jack and Jill are adult siblings.\n",
      "      The relationship has the following notes: twins\n",
      "  • There is a directed relationship from 'Jack' to 'Sam' called 'Friend'.\n",
      "      The relationship is described as: Jack and Sam are friends.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Jill' to 'Sam' called 'Friend'.\n",
      "      The relationship is described as: Jill and Sam are friends.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Sam' to 'Friend' called 'Matchmaker'.\n",
      "      The relationship is described as: Sam found love with the help of Jack and Jill's friend.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Sam' to 'Romania' called 'MovedTo'.\n",
      "      The relationship is described as: Sam and their friend moved to Romania.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Patient' to 'Metformin' called 'Prescribed'.\n",
      "      The relationship is described as: The patient was prescribed metformin 500mg twice daily.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Jack' to 'Jill' called 'UsedFor'.\n",
      "      The relationship is described as: MRI scans are used to diagnose brain tumors.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Jill' to 'Sam' called 'LocatedIn'.\n",
      "      The relationship is described as: The left temporal lobe is located in the brain.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Sam' to 'Friend' called 'TypeOf'.\n",
      "      The relationship is described as: Low-grade glioma is a type of glioma.\n",
      "      The relationship has the following notes: \n",
      "  • There is a directed relationship from 'Friend' to 'Romania' called 'TypeOf'.\n",
      "      The relationship is described as: Glioma is a type of brain tumor.\n",
      "      The relationship has the following notes: \n",
      "\n",
      "\n",
      "\n",
      "# INSTRUCTIONS\n",
      "Your goal is to provide a response to the user query using the relevant information in the input data:\n",
      "- the \"Entities\" and \"Relationships\" tables contain high-level information. Use these tables to identify the most important entities and relationships to respond to the query.\n",
      "- the \"Sources\" list contains raw text sources to help answer the query. It may contain noisy data, so pay attention when analyzing it.\n",
      "\n",
      "Follow these steps:\n",
      "1. Read and understand the user query.\n",
      "2. Look at the \"Entities\" and \"Relationships\" tables to get a general sense of the data and understand which information is the most relevant to answer the query.\n",
      "3. Carefully analyze all the \"Sources\" to get more detailed information. Information could be scattered across several sources, use the identified relevant entities and relationships to guide yourself through the analysis of the sources.\n",
      "4. While you write the response, you must include inline references to the all the sources you are using by appending `[<source_id>]` at the end of each sentence, where `source_id` is the corresponding source ID from the \"Sources\" list.\n",
      "5. Write the response to the user query - which must include the inline references - based on the information you have gathered. Be very concise and answer the user query directly. If the response cannot be inferred from the input data, just say no relevant information was found. Do not make anything up or add unrelevant information.\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 57 prefix-match hit, remaining 1147 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    9163.97 ms\n",
      "llama_perf_context_print: prompt eval time =   10635.08 ms /  1147 tokens (    9.27 ms per token,   107.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4664.64 ms /    99 runs   (   47.12 ms per token,    21.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   15811.75 ms /  1246 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the given data, we can answer the user query as follows:\\nJack is 45 years old [1]. The gender of Jill is not explicitly mentioned in the given data, so we cannot determine it. As for Sam's character arc, we do not have enough information to provide a comprehensive analysis. The story is set in Romania [2], where Sam and their friend moved to. \\n\\nReferences:\\n[1] - Entity description of Jack\\n[2] - Relationship between Sam and Romania\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Question:', queries[4])\n",
    "resp = rag.query(queries[4])\n",
    "resp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
