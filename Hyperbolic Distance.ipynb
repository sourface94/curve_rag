{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "520f9dc7-2720-4d87-adcd-761111996c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff816b1-a608-4916-a486-a810ec36029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from curverag.atth.kg_dataset import KGDataset\n",
    "from curverag.atth.models.hyperbolic import AttH\n",
    "from curverag.atth.utils.hyperbolic import hyp_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ea0c43-774d-42b0-b692-2007909ca62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data/medical_docs'\n",
    "dataset = KGDataset(dataset_path, debug=False, name='medical_docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b8ef14-30e3-40ef-9497-00955b335da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e83c827-0813-47c9-90b2-dc386ca059aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 48, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe0022e-c6ee-469e-ad7b-382e47ee788b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/nathan/Documents/projects/curve_rag/logs/05_01/medical_docs/AttH_23_03_31/model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m AttH(sizes\u001b[38;5;241m=\u001b[39msizes)\n\u001b[1;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/nathan/Documents/projects/curve_rag/logs/05_01/medical_docs/AttH_23_03_31/model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Documents/projects/curve_rag/.venv/lib/python3.10/site-packages/torch/serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/Documents/projects/curve_rag/.venv/lib/python3.10/site-packages/torch/serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/Documents/projects/curve_rag/.venv/lib/python3.10/site-packages/torch/serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/nathan/Documents/projects/curve_rag/logs/05_01/medical_docs/AttH_23_03_31/model.pt'"
     ]
    }
   ],
   "source": [
    "model = AttH(sizes=sizes)\n",
    "model_path = '/Users/nathan/Documents/projects/curve_rag/logs/05_01/medical_docs/AttH_23_03_31/model.pt'\n",
    "model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cb827bb-5391-48b3-b033-7639e2def424",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_embeddings = model.entity.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "957b6186-03cc-4fb1-874d-ec47e83ba79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_embs_1 = model.entity.weight.data[:10]\n",
    "entities_embs_2 = model.entity.weight.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab59fde8-852b-4c14-86e8-3f5472be4184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(entities_embs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a7d19fc-2d49-4278-aab3-bf6f17b69ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1009,  0.0997,  0.1011,  ...,  0.0994, -0.0992, -0.0872],\n",
       "        [ 0.0972,  0.1023, -0.0994,  ...,  0.0991,  0.0905,  0.0982],\n",
       "        [-0.0989,  0.1009, -0.0952,  ..., -0.0977,  0.0999,  0.0987]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.entity.weight.data[[0, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "baac3548-af42-40a1-b5db-6588dd148404",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor([1.0], dtype=model.entity.weight.data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fcc661ac-0696-49a9-b508-0445c9be1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = hyp_distance(entities_embs_1, entities_embs_2, c, eval_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d141bb7c-b017-4ee1-9320-68f6be38d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14a37d23-266c-460d-9eab-d133a46421c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5821e-08, 1.0228e+00, 1.0387e+00, 9.9058e-01, 1.0150e+00, 1.0115e+00,\n",
       "         1.0042e+00, 9.8303e-01, 9.6826e-01, 1.0056e+00],\n",
       "        [1.0228e+00, 1.8271e-08, 9.8176e-01, 9.7381e-01, 9.9466e-01, 9.7279e-01,\n",
       "         9.6559e-01, 9.7851e-01, 9.7131e-01, 9.8186e-01],\n",
       "        [1.0387e+00, 9.8176e-01, 0.0000e+00, 1.0204e+00, 9.9740e-01, 9.7583e-01,\n",
       "         9.7125e-01, 1.0017e+00, 1.0013e+00, 1.0143e+00],\n",
       "        [9.9058e-01, 9.7381e-01, 1.0204e+00, 1.8000e-08, 9.7836e-01, 9.7415e-01,\n",
       "         9.6307e-01, 9.6381e-01, 9.7829e-01, 9.6840e-01],\n",
       "        [1.0150e+00, 9.9466e-01, 9.9740e-01, 9.7836e-01,        nan, 9.7398e-01,\n",
       "         9.7391e-01, 9.6891e-01, 1.0059e+00, 9.7293e-01],\n",
       "        [1.0115e+00, 9.7279e-01, 9.7583e-01, 9.7415e-01, 9.7398e-01,        nan,\n",
       "         9.9011e-01, 9.7637e-01, 9.7809e-01, 9.8384e-01],\n",
       "        [1.0042e+00, 9.6559e-01, 9.7125e-01, 9.6307e-01, 9.7391e-01, 9.9011e-01,\n",
       "         0.0000e+00, 9.8260e-01, 9.6894e-01, 1.0141e+00],\n",
       "        [9.8303e-01, 9.7851e-01, 1.0017e+00, 9.6381e-01, 9.6891e-01, 9.7637e-01,\n",
       "         9.8260e-01,        nan, 9.6332e-01, 9.7599e-01],\n",
       "        [9.6826e-01, 9.7131e-01, 1.0013e+00, 9.7829e-01, 1.0059e+00, 9.7809e-01,\n",
       "         9.6894e-01, 9.6332e-01, 1.8675e-08, 1.0017e+00],\n",
       "        [1.0056e+00, 9.8186e-01, 1.0143e+00, 9.6840e-01, 9.7293e-01, 9.8384e-01,\n",
       "         1.0141e+00, 9.7599e-01, 1.0017e+00, 1.3795e-08]], dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd707432-7585-47ad-b1b5-e51332f82b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5821e-08, 1.0228e+00, 1.0387e+00, 9.9058e-01, 1.0150e+00, 1.0115e+00,\n",
       "        1.0042e+00, 9.8303e-01, 9.6826e-01, 1.0056e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc3c73e9-2b0e-4f5d-80b7-9632730d18e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 6, 5, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "scores, indices = torch.topk(distances[2], 5, largest=False)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9653dc3b-88a8-4e59-a35e-72941f5058b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  True,  True])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 1, 4])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "mask = scores > threshold\n",
    "print(mask)\n",
    "filtered_vals = scores[mask]\n",
    "filtered_indices = indices[mask]\n",
    "filtered_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb6a7b-002b-437f-8afb-c1e5b3ea9b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
